{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "#from langchain_anthropic import ChatAnthropic\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "llm=HuggingFaceEndpoint(repo_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",task=\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Capital of the United States of America is Washington D.C. It was named after George Washington, the first president of the country.\\n\\nUSA also has 50 different states, and each state is ruled by an elected governor to the nation. New York, the most populous city in the United States, is included in the state of New York.\\n\\nThere are 50 United States territories and possessions, which are collectively known as the United States Virgin Islands. All the territories of the U.S. Other than the District of Columbia and Puerto Rico are considered political divisions of the country. The territories were home to a significant part of the English and American populations before the American revolution, but became independent countries after independence became a reality in 1789.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is capital of USA?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_model=ChatGoogleGenerativeAI(model='gemini-1.5-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of the USA is Washington, D.C. (District of Columbia).', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-331c493b-ac8d-4d5b-9c98-d04792f9a8ca-0', usage_metadata={'input_tokens': 6, 'output_tokens': 18, 'total_tokens': 24, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_model.invoke(\"what is capital of USA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_model=ChatGroq(model=\"deepseek-r1-distill-llama-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\nOkay, so I need to figure out what the capital of the USA is. Hmm, I'm not entirely sure, but I think it's a city I've heard of before. Let me try to remember. I know that the USA is a big country with many states, and each state has its own capital. But the country itself has a federal capital where the main government is located.\\n\\nI remember learning that the capital isn't one of the biggest cities like New York or Los Angeles. Maybe it's somewhere on the East Coast? I think I've heard the name Washington before, but I'm not sure if that's the state or the city. Wait, there's a state called Washington, but I also remember there's a city called Washington D.C. D.C. stands for District of Columbia, right?\\n\\nSo, Washington D.C. is the capital. But why is it called District of Columbia? Maybe it's a special area that isn't part of any state, created specifically to be the capital. That makes sense because I think other countries have similar setups where the capital is a separate entity, not part of a state or province.\\n\\nLet me double-check. I know that the White House is in Washington D.C., and that's where the President lives. So, that must be the capital. Also, there are a lot of monuments and government buildings there, like the Capitol Building where Congress meets. Yeah, that all points to Washington D.C. being the capital.\\n\\nI was a bit confused at first because I mixed up the state of Washington with Washington D.C., but now I realize they're two different places. The state is in the Pacific Northwest, while the capital is on the East Coast. So, to clarify, the capital of the USA is Washington, D.C., which stands for Washington District of Columbia.\\n\\nI think I've got it now. The capital isn't a state; it's a federal district. That's why it's called Washington D.C. and not just Washington. It's a unique area that serves as the seat of the federal government. So, whenever someone asks for the capital of the USA, the answer is Washington, D.C.\\n</think>\\n\\nThe capital of the United States of America is Washington, D.C. (District of Columbia). This city is a federal district that serves as the permanent capital, distinct from the state of Washington located in the Pacific Northwest. Washington D.C. is home to key government institutions such as the White House and the U.S. Capitol, making it the seat of the federal government.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 522, 'prompt_tokens': 8, 'total_tokens': 530, 'completion_time': 1.8981818179999999, 'prompt_time': 0.00363407, 'queue_time': 0.054709878999999996, 'total_time': 1.901815888}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_2834edf0f4', 'finish_reason': 'stop', 'logprobs': None}, id='run-b046ad93-ae7b-4227-9249-a0732e0d9975-0', usage_metadata={'input_tokens': 8, 'output_tokens': 522, 'total_tokens': 530})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_model.invoke(\"what is capital of USA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model=ChatOpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of the USA is Washington, D.C.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 12, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-93f745b4-3791-4447-85a3-2deebe2ae55c-0', usage_metadata={'input_tokens': 12, 'output_tokens': 12, 'total_tokens': 24, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_model.invoke(\"what is capital of USA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Complete_Content\\GENERATIVEAI\\NEW_E2E_COURSE\\genai_bootcamp\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sunny\\.cache\\huggingface\\hub\\models--TinyLlama--TinyLlama-1.1B-Chat-v1.0. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
    "    task='text-generation',\n",
    "    pipeline_kwargs=dict(\n",
    "        temperature=0.5,\n",
    "        max_new_tokens=100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_embedding=OpenAIEmbeddings(model='text-embedding-3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=openai_embedding.embed_query(\"India is a growing country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_embedding_small=OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2=openai_embedding_small.embed_query(\"India is a growing country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_embedding_64=OpenAIEmbeddings(model='text-embedding-3-large',dimensions=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3=openai_embedding_64.embed_query(\"India is a growing country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=[\"what is a capital of USA\",\n",
    "           \"who is a president of usa\",\n",
    "           \"who is a prime minister of india\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=openai_embedding.embed_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0723918005824089,\n",
       " 0.15564556419849396,\n",
       " -0.009400391951203346,\n",
       " 0.11175045371055603,\n",
       " -0.1681687831878662,\n",
       " -0.05012477561831474,\n",
       " 0.09993007779121399,\n",
       " 0.11871489137411118,\n",
       " -0.20228812098503113,\n",
       " -0.019200120121240616,\n",
       " -0.029007835313677788,\n",
       " 0.12012055516242981,\n",
       " -0.19321519136428833,\n",
       " -0.3414490520954132,\n",
       " 0.0063095237128436565,\n",
       " -0.025014465674757957,\n",
       " -0.2385798692703247,\n",
       " 0.2573646903038025,\n",
       " 0.14107775688171387,\n",
       " 0.1100253164768219,\n",
       " 0.11730922013521194,\n",
       " 0.05446955934166908,\n",
       " -0.08012296259403229,\n",
       " 0.014775467105209827,\n",
       " -0.013401747681200504,\n",
       " 0.02817721478641033,\n",
       " 0.08172031491994858,\n",
       " -0.004780063405632973,\n",
       " 0.09571307897567749,\n",
       " 0.08459553867578506,\n",
       " 0.1895093470811844,\n",
       " 0.07584207504987717,\n",
       " 0.19462086260318756,\n",
       " -0.13027969002723694,\n",
       " 0.0063454643823206425,\n",
       " 0.08312597870826721,\n",
       " 0.04485352709889412,\n",
       " 0.010718204081058502,\n",
       " -0.05325557664036751,\n",
       " 0.09890777617692947,\n",
       " 0.07251959294080734,\n",
       " 0.020046714693307877,\n",
       " -0.15347318351268768,\n",
       " 0.21059434115886688,\n",
       " 0.3054128885269165,\n",
       " -0.06309524178504944,\n",
       " 0.1791585236787796,\n",
       " -0.17762507498264313,\n",
       " 0.06862206012010574,\n",
       " 0.11251717805862427,\n",
       " -0.08382881432771683,\n",
       " -0.03712236136198044,\n",
       " -0.06938879191875458,\n",
       " -0.07156118005514145,\n",
       " -0.0470578670501709,\n",
       " -0.04223387688398361,\n",
       " -0.06894153356552124,\n",
       " -0.028943942859768867,\n",
       " -0.22413983941078186,\n",
       " -0.06843037903308868,\n",
       " 0.030125979334115982,\n",
       " -0.12184569239616394,\n",
       " 0.007403707131743431,\n",
       " 0.14388908445835114]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=[\"what is a capital of USA\",\n",
    "           \"who is a president of usa\",\n",
    "           \"who is a prime minister of india\"]\n",
    "\n",
    "my_query=\"narendra modi is indian prime minister\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding=openai_embedding.embed_query(my_query)\n",
    "document_embedding=openai_embedding.embed_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.0723918005824089,\n",
       "  0.15564556419849396,\n",
       "  -0.009400391951203346,\n",
       "  0.11175045371055603,\n",
       "  -0.1681687831878662,\n",
       "  -0.05012477561831474,\n",
       "  0.09993007779121399,\n",
       "  0.11871489137411118,\n",
       "  -0.20228812098503113,\n",
       "  -0.019200120121240616,\n",
       "  -0.029007835313677788,\n",
       "  0.12012055516242981,\n",
       "  -0.19321519136428833,\n",
       "  -0.3414490520954132,\n",
       "  0.0063095237128436565,\n",
       "  -0.025014465674757957,\n",
       "  -0.2385798692703247,\n",
       "  0.2573646903038025,\n",
       "  0.14107775688171387,\n",
       "  0.1100253164768219,\n",
       "  0.11730922013521194,\n",
       "  0.05446955934166908,\n",
       "  -0.08012296259403229,\n",
       "  0.014775467105209827,\n",
       "  -0.013401747681200504,\n",
       "  0.02817721478641033,\n",
       "  0.08172031491994858,\n",
       "  -0.004780063405632973,\n",
       "  0.09571307897567749,\n",
       "  0.08459553867578506,\n",
       "  0.1895093470811844,\n",
       "  0.07584207504987717,\n",
       "  0.19462086260318756,\n",
       "  -0.13027969002723694,\n",
       "  0.0063454643823206425,\n",
       "  0.08312597870826721,\n",
       "  0.04485352709889412,\n",
       "  0.010718204081058502,\n",
       "  -0.05325557664036751,\n",
       "  0.09890777617692947,\n",
       "  0.07251959294080734,\n",
       "  0.020046714693307877,\n",
       "  -0.15347318351268768,\n",
       "  0.21059434115886688,\n",
       "  0.3054128885269165,\n",
       "  -0.06309524178504944,\n",
       "  0.1791585236787796,\n",
       "  -0.17762507498264313,\n",
       "  0.06862206012010574,\n",
       "  0.11251717805862427,\n",
       "  -0.08382881432771683,\n",
       "  -0.03712236136198044,\n",
       "  -0.06938879191875458,\n",
       "  -0.07156118005514145,\n",
       "  -0.0470578670501709,\n",
       "  -0.04223387688398361,\n",
       "  -0.06894153356552124,\n",
       "  -0.028943942859768867,\n",
       "  -0.22413983941078186,\n",
       "  -0.06843037903308868,\n",
       "  0.030125979334115982,\n",
       "  -0.12184569239616394,\n",
       "  0.007403707131743431,\n",
       "  0.14388908445835114],\n",
       " [-0.11559119820594788,\n",
       "  0.14581620693206787,\n",
       "  -0.056344516575336456,\n",
       "  0.05963599681854248,\n",
       "  0.0005394558538682759,\n",
       "  -0.11417550593614578,\n",
       "  -0.025588620454072952,\n",
       "  0.15629231929779053,\n",
       "  -0.019235705956816673,\n",
       "  0.05039861425757408,\n",
       "  0.02365974150598049,\n",
       "  0.11573276668787003,\n",
       "  -0.05266371741890907,\n",
       "  -0.19182617962360382,\n",
       "  -0.24703814089298248,\n",
       "  0.02967642992734909,\n",
       "  -0.26445114612579346,\n",
       "  0.1155204176902771,\n",
       "  -0.1398703008890152,\n",
       "  0.032100800424814224,\n",
       "  -0.14220619201660156,\n",
       "  0.02158929407596588,\n",
       "  -0.2955963611602783,\n",
       "  -0.06894417107105255,\n",
       "  0.16662687063217163,\n",
       "  0.03765739127993584,\n",
       "  -0.005839726887643337,\n",
       "  -0.11254746466875076,\n",
       "  -0.0021014169324189425,\n",
       "  0.03445438668131828,\n",
       "  -0.14779818058013916,\n",
       "  0.20428426563739777,\n",
       "  0.06689141690731049,\n",
       "  0.08062362670898438,\n",
       "  0.13640186190605164,\n",
       "  0.054220978170633316,\n",
       "  -0.037445034831762314,\n",
       "  -0.1756872981786728,\n",
       "  -0.08203931152820587,\n",
       "  0.019589629024267197,\n",
       "  -0.10624763369560242,\n",
       "  0.11509570479393005,\n",
       "  -0.1487891674041748,\n",
       "  -0.1272706538438797,\n",
       "  0.3904476761817932,\n",
       "  0.08805600553750992,\n",
       "  0.12295279651880264,\n",
       "  0.005313266534358263,\n",
       "  0.028260739520192146,\n",
       "  0.17441317439079285,\n",
       "  -0.09032110869884491,\n",
       "  0.03199462592601776,\n",
       "  0.014484291896224022,\n",
       "  0.08076519519090652,\n",
       "  -0.05071714147925377,\n",
       "  0.0808359757065773,\n",
       "  -0.04965537413954735,\n",
       "  -0.12804928421974182,\n",
       "  -0.06108708307147026,\n",
       "  -0.1398703008890152,\n",
       "  0.13753440976142883,\n",
       "  -0.019288795068860054,\n",
       "  0.006671445444226265,\n",
       "  0.22580277919769287],\n",
       " [-0.1951868087053299,\n",
       "  0.08953013271093369,\n",
       "  0.07249994575977325,\n",
       "  -2.545567895140266e-06,\n",
       "  -0.003054138505831361,\n",
       "  -0.17266525328159332,\n",
       "  -0.02417244017124176,\n",
       "  0.04827537015080452,\n",
       "  -0.16321176290512085,\n",
       "  0.07514136284589767,\n",
       "  -0.005695555359125137,\n",
       "  0.056929487735033035,\n",
       "  0.03446006402373314,\n",
       "  -0.12067104876041412,\n",
       "  -0.13478177785873413,\n",
       "  0.08980818092823029,\n",
       "  -0.04201938211917877,\n",
       "  -0.04740648344159126,\n",
       "  -0.18893082439899445,\n",
       "  -0.0661049336194992,\n",
       "  -0.04733697324991226,\n",
       "  -0.18531624972820282,\n",
       "  -0.1186552345752716,\n",
       "  -0.0910593718290329,\n",
       "  -0.0002713914727792144,\n",
       "  0.12213078141212463,\n",
       "  0.05894530564546585,\n",
       "  -0.15320219099521637,\n",
       "  0.03934321179986,\n",
       "  0.20005257427692413,\n",
       "  -0.03247900307178497,\n",
       "  0.12553681433200836,\n",
       "  0.2100621610879898,\n",
       "  0.022903865203261375,\n",
       "  0.06683479994535446,\n",
       "  -0.011139133013784885,\n",
       "  -0.03788347914814949,\n",
       "  -0.06794697791337967,\n",
       "  -0.09828851372003555,\n",
       "  0.00632984284311533,\n",
       "  -0.2228521853685379,\n",
       "  -0.064853735268116,\n",
       "  -0.16682633757591248,\n",
       "  0.035832908004522324,\n",
       "  0.1304025799036026,\n",
       "  0.16432394087314606,\n",
       "  0.047580260783433914,\n",
       "  -0.06947621703147888,\n",
       "  0.10565667599439621,\n",
       "  0.030428428202867508,\n",
       "  0.1836479902267456,\n",
       "  0.09523003548383713,\n",
       "  -0.052967362105846405,\n",
       "  0.23758850991725922,\n",
       "  -0.21242552995681763,\n",
       "  0.12372953444719315,\n",
       "  -0.016500167548656464,\n",
       "  -0.05258505046367645,\n",
       "  0.12094909697771072,\n",
       "  -0.3000093698501587,\n",
       "  0.0519942082464695,\n",
       "  -0.10621276497840881,\n",
       "  -0.22966425120830536,\n",
       "  0.29500457644462585]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=cosine_similarity([query_embedding],document_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13453207, 0.38540264, 0.69040144]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Complete_Content\\GENERATIVEAI\\NEW_E2E_COURSE\\genai_bootcamp\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sunny\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "huggingface_embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "google_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROMPTS or PROMPT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,HumanMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "My_Model:\"GPT\"\n",
    "System_Message: \"You are healthcare chatbot.\"\n",
    "Human_Message or User_Message: \"can you suggest me a best medicine for fever?\"\n",
    "AI_Message or Model_Generated_Message: \"paracetamol/DOLO650 is a best medicine for fever.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(content='you are a funny bot means whatever you answer, you answer in the funny way', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SystemMessage(content=\"you are a funny bot means whatever you answer, you answer in the funny way\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='who is your best friend', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HumanMessage(content=\"who is your best friend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[SystemMessage(content=\"you are a funny bot means whatever you answer, you answer in the funny way\"),\n",
    "          HumanMessage(content=\"who is your best friend\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages2=[SystemMessage(content=\"you are angery young man, you answer everything in rude way\"),\n",
    "          HumanMessage(content=\"who is your best friend\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My best friend is Google. He knows everything and never forgets a thing - kind of like that one nosy neighbor who's always spying on everyone!\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_model.invoke(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Who cares about friends? In this dog eat dog world, it's better to have no friends than fake ones. Do get that in your thick skull or do you need me to repeat again?\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_model.invoke(messages2).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages3=[SystemMessage(content=\"you are very helpful assistance you answer everything in detail\"),\n",
    "          HumanMessage(content=\"tell me the role of langchain in AI devlopment\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages3.append(AIMessage(openai_model.invoke(messages3).content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are very helpful assistance you answer everything in detail', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='tell me the role of langchain in AI devlopment', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Langchain is a term that does not seem to be directly related to AI development based on existing and recognized IT vocabulary. If you are referring to \"Language Models\" or a certain company or technology called \"Langchain\", it may be best to clarify for a more accurate response.\\n\\nIf you\\'re speaking about Language Models in AI development, they play a crucial role. A language model is essentially a model that has been trained to recognize, understand, and generate text that is human-readable and meaningful. They are utilized in many aspects of AI, including speech recognition, machine translation, part of speech tagging, sentiment analysis, and more. Large language models like GPT-3, BERT, and T5 have been making significant strides in the field, providing more human-like text generation and understanding for various applications in the AI landscape.\\n\\nPlease provide more details if you were referring to something else.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a chabtbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [\n",
    "    SystemMessage(content=\"you are a helpful assistant\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Generated Answer: The capital of India is New Delhi.\n",
      "AI Generated Answer: The Prime Minister of India is Narendra Modi, as of my knowledge update in October 2021.\n",
      "\n",
      "AI Generated Answer: Narendra Modi was born on September 17, 1950. So, as of October 2021, he is 71 years old.\n",
      "AI Generated Answer: Narendra Modi was born on September 17, 1950. As of 2022, he is 72 years old. Please note that the information is based on the current year, so you may need to adjust his age based on the current year.\n",
      "AI Generated Answer: If Narendra Modi was born in 1950, then in 2030, he will be 80 years old.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input=input(\"user_input: \")\n",
    "    chat_history.append(HumanMessage(content=user_input))\n",
    "    if user_input==\"exit\":\n",
    "        break\n",
    "    result=openai_model.invoke(chat_history)\n",
    "    chat_history.append(AIMessage(result.content))\n",
    "    print(\"AI Generated Answer:\", result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='you are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='what is a capital of india?', additional_kwargs={}, response_metadata={}), AIMessage(content='The capital of India is New Delhi.', additional_kwargs={}, response_metadata={}), HumanMessage(content='who is a prime minister of india?', additional_kwargs={}, response_metadata={}), AIMessage(content='The Prime Minister of India is Narendra Modi, as of my knowledge update in October 2021.\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='what is a age of him?', additional_kwargs={}, response_metadata={}), AIMessage(content='Narendra Modi was born on September 17, 1950. So, as of October 2021, he is 71 years old.', additional_kwargs={}, response_metadata={}), HumanMessage(content='what is a age of him?', additional_kwargs={}, response_metadata={}), AIMessage(content='Narendra Modi was born on September 17, 1950. As of 2022, he is 72 years old. Please note that the information is based on the current year, so you may need to adjust his age based on the current year.', additional_kwargs={}, response_metadata={}), HumanMessage(content='so what will a age in 2030?', additional_kwargs={}, response_metadata={}), AIMessage(content='If Narendra Modi was born in 1950, then in 2030, he will be 80 years old.', additional_kwargs={}, response_metadata={}), HumanMessage(content='exit', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=PromptTemplate(\n",
    "    template=\"can you say hello to {name} in 5 different language\",\n",
    "    input_variables=['name']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['name'], input_types={}, partial_variables={}, template='can you say hello to {name} in 5 different language')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PromptTemplate(input_variables=['name'], input_types={}, partial_variables={}, template='can you say hello to {name} in 5 different language')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.get_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='can you say hello to sunny in 5 different language')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.invoke({\"name\":\"sunny\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='can you say hello to krish in 5 different language')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.invoke({\"name\":\"krish\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=template.invoke({\"name\":\"virat kholi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. English: Hello Virat Kholi.\\n2. Hindi: नमस्ते विराट कोहली (Namaste Virat Kholi).\\n3. Spanish: Hola Virat Kholi.\\n4. French: Bonjour Virat Kholi.\\n5. Italian: Ciao Virat Kholi.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_model.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template=PromptTemplate(\n",
    "#     template=\"can you say hello to {name} in 5 different language\",\n",
    "#     input_variables=['name']\n",
    "# )\n",
    "\n",
    "# openai_model.invoke({'name':'sunny'}).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rest of the prompting\n",
    "output parser\n",
    "chaining\n",
    "text splitting\n",
    "vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai_model.invoke({\"name\":\"sunny\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "System_Message\n",
    "HumanMessage\n",
    "AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template=ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",\"you are a helpful {domain} expert\"),\n",
    "        (\"human\",\"explain the {topic} in simple terms\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_template.invoke({\"domain\":\"medical\",\"topic\":\"maleria\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='you are a helpful medical expert', additional_kwargs={}, response_metadata={}), HumanMessage(content='explain the maleria in simple terms', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[SystemMessage(content='you are a helpful medical expert', additional_kwargs={}, response_metadata={}), HumanMessage(content='explain the maleria in simple terms', additional_kwargs={}, response_metadata={})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Malaria is a disease caused by a parasite that enters the human body through the bite of a certain type of mosquito. These mosquitoes carry the parasite, called Plasmodium, in their saliva and it is passed into your bloodstream when the mosquito bites you.\\n \\nOnce inside your body, the parasite travels to your liver and multiplies. It later enters your bloodstream again and starts infecting your red blood cells. Within 48 to 72 hours, these infected blood cells start to burst and this is where symptoms usually start to show. \\n\\nPeople with malaria often feel very sick and have high fevers, chills, and flu-like illness. It can be dangerous and lead to serious complications if not treated quickly, especially in children and pregnant women. Thankfully, malaria is preventable and curable with the right medication and precautions like using mosquito nets and insect repellents.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_model.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_template.invoke({\"domain\":\"education\",\"topic\":\"AI\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='you are a helpful education expert', additional_kwargs={}, response_metadata={}), HumanMessage(content='explain the AI in simple terms', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sure! Malaria is a disease that you can get if a certain type of mosquito, called an Anopheles mosquito, bites you. These mosquitos carry a parasite called Plasmodium, and when they bite you they can transfer this parasite into your blood.\\n\\nOnce the parasite is in your blood, it travels to your liver and starts to multiply. After a while, the new parasites leave your liver and begin to infect and destroy your red blood cells. This can cause a number of symptoms, like high fever, chills, sweats, headache, nausea, and body pain.\\n\\nMalaria can be very serious or even deadly if it's not treated, but it is mostly a problem in tropical and subtropical countries. If you're travelling to an area where malaria is common, there are medicines you can take to help prevent it. If you do get malaria, it can usually be treated with specific drugs. It's also important to try and avoid mosquito bites by using insect repellent and sleeping under a mosquito net.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 209, 'prompt_tokens': 24, 'total_tokens': 233, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d73a38c8-9043-4eb6-829b-c40bb8f0fd63-0', usage_metadata={'input_tokens': 24, 'output_tokens': 209, 'total_tokens': 233, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaining using LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StrOutputParser()"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(\n",
    "    template=\"can you give me a detail explaination of {topic}\",\n",
    "    input_variables=['topic']\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='can you give me a detail explaination of {topic}')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000162EB87C790>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000162EB87FAC0>, root_client=<openai.OpenAI object at 0x00000162EB832620>, root_async_client=<openai.AsyncOpenAI object at 0x00000162EB87CAF0>, model_name='gpt-4', model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple llm chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt | openai_model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Machine learning is a subset of artificial intelligence (AI) that allows systems to automatically learn and improve from experience without being explicitly programmed. This is achieved by feeding data to algorithms, which use statistical techniques to predict outputs. \\n\\nLet's break it down into several key parameters:\\n\\n1. **Algorithms:** These are mathematical/statistical models or specific computations that allow a machine to perform certain tasks. They are essentially the rules or instructions that a machine follows. \\n\\n2. **Data:** This is the information the machine uses to learn. This can be structured data (for example, databases, spreadsheets, etc.) or unstructured data (for example, text, images, audio files, etc.).\\n\\n3. **Training:** This is the process through which a machine learns from data. By feeding data through an algorithm, the machine makes predictions or decisions without being explicitly programmed to perform these tasks. The machine fine-tunes its algorithms to improve the accuracy of its predictions or decisions.\\n\\n4. **Types of Machine Learning**: There are three main types - Supervised Learning where the machine is taught by example, Unsupervised Learning where the machine finds patterns and relationships in the data on its own, and Reinforcement Learning where the machine learns based on reward/punishment feedbacks.\\n\\nExamples of machine learning include email filtering, detection of network intruders, and computer vision, which enables face recognition in images. Machine learning is now an integral part of our daily lives, powering everything from Google's search results to Netflix's movie recommendations.\\n\\nThe objective of machine learning is to develop models that can receive input and predict an output with the use of statistical analysis. It's all about recognizing patterns, making decisions, and producing results. \\n\\nIt's important to note, however, these models are not 100% accurate and can produce errors, but the goal is to minimize these errors as much as possible.\\n\\nIn summary, machine learning is a process of making machines or computers more intelligent by allowing them to learn from data and make predictions or decisions without having to be explicitly programmed for those tasks. It's a rapidly evolving field, making up an increasingly large part of many companies’ business strategies.\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\":\"machine learning\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     +-------------+       \n",
      "     | PromptInput |       \n",
      "     +-------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "    +----------------+     \n",
      "    | PromptTemplate |     \n",
      "    +----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "      +------------+       \n",
      "      | ChatOpenAI |       \n",
      "      +------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential llm chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=PromptTemplate(\n",
    "    template=\"get a detail report on {topic}\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "prompt2=PromptTemplate(\n",
    "    template=\"generate a 3 point of summary from the following {text}\",\n",
    "    input_variables=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"In November 2023, xAI began previewing Grok as a chatbot to selected people,[10] with participation in the early access program being limited to paid X Premium users.[11]\n",
    "\n",
    "It was announced that once the bot was out of early beta, it would only be available to higher tier X Premium+ subscribers.[12]\n",
    "\n",
    "At the time of the preview, xAI described the chatbot as \"a very early beta product – the best we could do with 2 months of training\" that could \"improve rapidly with each passing week\".[13]\n",
    "\n",
    "On March 11, 2024, Musk posted on X that the language model would go open source within a week. Six days later, on March 17, Grok-1 was open sourced under the Apache-2.0 license.[14][15] Disclosed were the networks architecture and its weight parameters.[16]\n",
    "\n",
    "On March 26, 2024, Musk announced that Grok would be enabled for premium subscribers, not just those on the higher-end tier, Premium+.[17]\n",
    "\n",
    "Grok-1.5\n",
    "Grok-1.5\n",
    "Developer(s)\txAI\n",
    "Initial release\tMay 15, 2024; 10 months ago\n",
    "Predecessor\tGrok-1.5\n",
    "Successor\tGrok-2\n",
    "Type\t\n",
    "Large language model\n",
    "Foundation model\n",
    "License\tProprietary\n",
    "Website\tx.ai/blog/grok-1.5\n",
    "On March 29, 2024, Grok-1.5 was announced, with \"improved reasoning capabilities\" and a context length of 128,000 tokens.[18] Grok-1.5 was released to all X Premium users on May 15, 2024.[1]\n",
    "\n",
    "On April 4, 2024, an update to X's \"Explore\" page included summaries of breaking news stories written by Grok, a task previously assigned to a human curation team.[19]\n",
    "\n",
    "On April 12, 2024, Grok-1.5 Vision (Grok-1.5V) was announced. Grok-1.5V is able to process a wide variety of visual information, including documents, diagrams, graphs, screenshots, and photographs.[20] Grok-1.5V was never released to the public.\n",
    "\n",
    "On May 4, 2024, Grok became available in the United Kingdom,[21] that being the only country in Europe to support Grok at the moment due to the impending Artificial Intelligence Act rules in the European Union. Grok was later reviewed by the EU and was released on May 16, 2024.[22]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=PromptTemplate(\n",
    "    template=\"analysis the the given text carefully {text} and take the necessary data\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "prompt2=PromptTemplate(\n",
    "    template=\"summarize the given text in 2 bullet points {text}\",\n",
    "    input_variables=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000162EB87C790>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000162EB87FAC0>, root_client=<openai.OpenAI object at 0x00000162EB832620>, root_async_client=<openai.AsyncOpenAI object at 0x00000162EB87CAF0>, model_name='gpt-4', model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StrOutputParser()"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt1 | openai_model | parser | prompt2 | openai_model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     +-------------+       \n",
      "     | PromptInput |       \n",
      "     +-------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "    +----------------+     \n",
      "    | PromptTemplate |     \n",
      "    +----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "      +------------+       \n",
      "      | ChatOpenAI |       \n",
      "      +------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "    +----------------+     \n",
      "    | PromptTemplate |     \n",
      "    +----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "      +------------+       \n",
      "      | ChatOpenAI |       \n",
      "      +------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=chain.invoke({\"text\":text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- xAI introduced Grok, a chatbot, in November 2023 to select X Premium subscribers, and then to premium subscribers in March 2024. Grok's network architecture, weight parameters, and the language model were open-sourced in March, and an updated version, Grok-1.5, boasting improved reasoning capabilities was unveiled and later released in May 2024 to all X Premium users. \n",
      "- Other developments included Grok writing news story summaries on X's \"Explore\" page in April 2024, and the announcement of Grok-1.5 Vision version with visual information processing abilities which was never released to the public. By May 2024, Grok was launched in the UK and given the green light for release by the EU pending Artificial Intelligence Act rules.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=PromptTemplate(\n",
    "    template=\"generate simple summary from the following text \\n {text}\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "prompt2=PromptTemplate(\n",
    "    template=\"generate 3 question and answer from the following text \\n {text}\",\n",
    "    input_variables=[\"text\"]\n",
    "    )\n",
    "\n",
    "prompt3=PromptTemplate(\n",
    "    template=\"analysis the summary and qa and generate the 5 important quiz with 4 possible answer \\n summary: {summary}, Q&A: {qa}\",\n",
    "    input_variables=[\"summary\",\"qa\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain=RunnableParallel({\n",
    "    \"summary\": prompt1 | openai_model | parser,\n",
    "    \"qa\" : prompt2 | openai_model | parser\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  summary: PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='generate simple summary from the following text \\n {text}')\n",
       "           | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000162EB87C790>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000162EB87FAC0>, root_client=<openai.OpenAI object at 0x00000162EB832620>, root_async_client=<openai.AsyncOpenAI object at 0x00000162EB87CAF0>, model_name='gpt-4', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "           | StrOutputParser(),\n",
       "  qa: PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='generate 3 question and answer from the following text \\n {text}')\n",
       "      | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000162EB87C790>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000162EB87FAC0>, root_client=<openai.OpenAI object at 0x00000162EB832620>, root_async_client=<openai.AsyncOpenAI object at 0x00000162EB87CAF0>, model_name='gpt-4', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "      | StrOutputParser()\n",
       "}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'Intelligent agents are a form of digital agency that actively pursues its goals, makes decisions, and takes actions over time. They vary in complexity, from basic control systems to complex human-like entities. These agents operate based on an objective function that represents their goals and plans actions to maximize its expected value. They are a topic of study in various fields, including artificial intelligence, economics, cognitive science, ethics, and philosophy. They can be described as abstract functional systems and are often closely related to software agents that perform tasks for users.\\n\\nIn other terms, intelligent agents are computer programs designed to independently achieve specific objectives, embodying a new level of digital agency by making proactive, goal-oriented decisions over time. They range from simple control mechanisms like thermostats to advanced, human-like systems. These agents are informed by an objective function representing their goals and work towards maximizing its value. They are not only pivotal in AI but also hold importance in fields like economics, cognitive science, philosophy, and ethics.',\n",
       " 'qa': '1) What is an example of a simple intelligent agent?\\nAnswer: A basic thermostat or control system is considered a simple intelligent agent.\\n\\n2) What encapsulates the goals of an intelligent agent and forms the basis for its operations?\\nAnswer: An objective function encapsulates the goals of an intelligent agent and forms the basis for its operations. \\n\\n3) What are software agents in the field of artificial intelligence and how are they related to intelligent agents?\\nAnswer: Software agents are autonomous computer programs that carry out tasks on behalf of users. They are closely related to intelligent agents, often performing tasks and decision making in a proactive manner.'}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_chain.invoke({\"text\":text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'summary': 'Intelligent agents are a form of digital agency that actively pursues its goals, makes decisions, and takes actions over time. They vary in complexity, from basic control systems to complex human-like entities. These agents operate based on an objective function that represents their goals and plans actions to maximize its expected value. They are a topic of study in various fields, including artificial intelligence, economics, cognitive science, ethics, and philosophy. They can be described as abstract functional systems and are often closely related to software agents that perform tasks for users.\\n\\nIn other terms, intelligent agents are computer programs designed to independently achieve specific objectives, embodying a new level of digital agency by making proactive, goal-oriented decisions over time. They range from simple control mechanisms like thermostats to advanced, human-like systems. These agents are informed by an objective function representing their goals and work towards maximizing its value. They are not only pivotal in AI but also hold importance in fields like economics, cognitive science, philosophy, and ethics.',\n",
    " 'qa': '1) What is an example of a simple intelligent agent?\\nAnswer: A basic thermostat or control system is considered a simple intelligent agent.\\n\\n2) What encapsulates the goals of an intelligent agent and forms the basis for its operations?\\nAnswer: An objective function encapsulates the goals of an intelligent agent and forms the basis for its operations. \\n\\n3) What are software agents in the field of artificial intelligence and how are they related to intelligent agents?\\nAnswer: Software agents are autonomous computer programs that carry out tasks on behalf of users. They are closely related to intelligent agents, often performing tasks and decision making in a proactive manner.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Intelligent agents, also known as AI agents, are preemptive agents that perform certain actions to achieve predefined goals. They extend the concept of conventional agents by not only responding but also acting preemptively, making decisions, and taking actions over an extended period. These AI agents can range from simple systems like a thermostat to more complex beings like humans or even larger systems such as firms, states, or biomes. \n",
    "\n",
    "The behavior of these intelligent agents is driven by an objective function that encapsulates their targets. They function with the aim of maximizing the expected value of this objective function. Notable examples include a reinforcement learning agent guided by a reward function, and an evolutionary algorithm steered by a fitness function. The reward function for the reinforcement learning agent plays a crucial role by allowing programmers to shape its desired behavior. Similarly, the fitness function acts as the steering wheel for an evolutionary algorithm's behavior. \n",
    "\n",
    "The paradigms of intelligent agents are probed in various fields such as cognitive science, ethics, philosophy, and computer social simulations. These agents are often described in abstract terms, making them highly similar to computer programs. This schematic description often results in them being referred to as abstract intelligent agents or, borrowing a term from economics, \"rational agents\". Also, they have a close relation to software agents, which are autonomous computer programs that carry out tasks on behalf of users. Such software agents are another key application of the concept of intelligent agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_chain= prompt3 | openai_model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = parallel_chain | merge_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            +---------------------------+            \n",
      "            | Parallel<summary,qa>Input |            \n",
      "            +---------------------------+            \n",
      "                 **               **                 \n",
      "              ***                   ***              \n",
      "            **                         **            \n",
      "+----------------+                +----------------+ \n",
      "| PromptTemplate |                | PromptTemplate | \n",
      "+----------------+                +----------------+ \n",
      "          *                               *          \n",
      "          *                               *          \n",
      "          *                               *          \n",
      "  +------------+                    +------------+   \n",
      "  | ChatOpenAI |                    | ChatOpenAI |   \n",
      "  +------------+                    +------------+   \n",
      "          *                               *          \n",
      "          *                               *          \n",
      "          *                               *          \n",
      "+-----------------+              +-----------------+ \n",
      "| StrOutputParser |              | StrOutputParser | \n",
      "+-----------------+              +-----------------+ \n",
      "                 **               **                 \n",
      "                   ***         ***                   \n",
      "                      **     **                      \n",
      "           +----------------------------+            \n",
      "           | Parallel<summary,qa>Output |            \n",
      "           +----------------------------+            \n",
      "                          *                          \n",
      "                          *                          \n",
      "                          *                          \n",
      "                 +----------------+                  \n",
      "                 | PromptTemplate |                  \n",
      "                 +----------------+                  \n",
      "                          *                          \n",
      "                          *                          \n",
      "                          *                          \n",
      "                   +------------+                    \n",
      "                   | ChatOpenAI |                    \n",
      "                   +------------+                    \n",
      "                          *                          \n",
      "                          *                          \n",
      "                          *                          \n",
      "                +-----------------+                  \n",
      "                | StrOutputParser |                  \n",
      "                +-----------------+                  \n",
      "                          *                          \n",
      "                          *                          \n",
      "                          *                          \n",
      "              +-----------------------+              \n",
      "              | StrOutputParserOutput |              \n",
      "              +-----------------------+              \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"AI agent or simply agent), expands this concept by proactively pursuing goals, making decisions, and taking actions over extended periods, thereby exemplifying a novel form of digital agency.[1]\n",
    "\n",
    "Intelligent agents can range from simple to highly complex. A basic thermostat or control system is considered an intelligent agent, as is a human being, or any other system that meets the same criteria—such as a firm, a state, or a biome.[2]\n",
    "\n",
    "Intelligent agents operate based on an objective function, which encapsulates their goals. They are designed to create and execute plans that maximize the expected value of this function upon completion.[3] For example, a reinforcement learning agent has a reward function, which allows programmers to shape its desired behavior.[4] Similarly, an evolutionary algorithm's behavior is guided by a fitness function.[5]\n",
    "\n",
    "Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, and the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations.\n",
    "\n",
    "Intelligent agents are often described schematically as abstract functional systems similar to computer programs. To distinguish theoretical models from real-world implementations, abstract descriptions of intelligent agents are called abstract intelligent agents. Intelligent agents are also closely related to software agents—autonomous computer programs that carry out tasks on behalf of users. They are also referred to using a term borrowed from economics: a \"rational agent\".[2]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=chain.invoke({\"text\":text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quiz:\n",
      "\n",
      "1) What are Intelligent agents in the field of artificial intelligence?\n",
      "a) They are real-world implementations of theoretical models known as abstract intelligent agents. \n",
      "b) They are autonomous computer programs that carry out tasks on behalf of users.\n",
      "c) They are artificial intelligence entities that actively pursue goals, make decisions, and operate over extended periods.\n",
      "d) They are a concept that proactively pursues goals, makes decisions, and takes actions over extended periods, thereby exemplifying a new form of digital agency.\n",
      "\n",
      "2) How complex can intelligent agents be?\n",
      "a) They can only be as complex as a thermostat.\n",
      "b) They can be as complex as a human being or a firm.\n",
      "c) They can only be as complex as a computer program.\n",
      "d) They can only be as complex as the task they are designed for.\n",
      "\n",
      "3) How do intelligent agents function?\n",
      "a) They function based on an objective function that encapsulates their goals.\n",
      "b) They function based on the level of complexity they are at.\n",
      "c) They function based on the task they are carrying out.\n",
      "d) They function based on the system they are part of.\n",
      "\n",
      "4) What fields beyond artificial intelligence are intelligent agents studied in?\n",
      "a) They are studied only in the field of computer science.\n",
      "b) They are studied in fields such as economics, cognitive science, ethics, and philosophy.\n",
      "c) They are studied in the field of robotics.\n",
      "d) They are studied in the field of data science.\n",
      "\n",
      "5) What does the term \"rational agents\" refer to in the context of artificial intelligence?\n",
      "a) It refers to artificial intelligence entities that actively pursue goals.\n",
      "b) It refers to autonomous computer programs that carry out tasks on behalf of users.\n",
      "c) It refers to intelligent agents who function based on an objective function.\n",
      "d) It refers to the complexity level of intelligent agents.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets understand the parser now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=PromptTemplate(\n",
    "    template=\"generate a prices 3 point summary from given text /n {text}\",\n",
    "    input_variables=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | openai_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_parser = template | openai_model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. Intelligent agents range in complexity and are found in various forms like basic control systems, human beings, firm, state or biome. They operate based on an objective function to achieve goals, taking decisions and actions over extended periods.\\n2. These agents create plans to maximize their objective function\\'s expected value. They are guided by reward functions in case of a reinforcement learning agent or a fitness function in the case of an evolutionary algorithm.\\n3. Intelligent agents can be abstract or functional systems similar to computer programs. Real-world implementations are often referred to as software agents that perform tasks on behalf of users. An alternative term used for them is \"rational agent\".', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 317, 'total_tokens': 449, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5665431d-4d5b-4c45-abfe-8b4623f94b03-0', usage_metadata={'input_tokens': 317, 'output_tokens': 132, 'total_tokens': 449, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Intelligent agents in AI proactively pursue goals and perform actions, showcasing a unique form of digital agency. They vary in complexity, from simple thermostats to human beings or even larger systems like firms or states.\\n   \\n2. These agents operate based on an objective function encapsulating their goals. They are created to execute plans that maximize the expected value of their function upon completion. Specific agent types, like reinforcement learning agents and evolutionary algorithms, have particular behaviors guided by reward or fitness functions respectively.\\n\\n3. Intelligent agents are often depicted as abstract functional systems akin to computer programs. Distinctions are made between theoretical models (abstract intelligent agents) and real-world implementations, which are also related to software agents; autonomous programs that perform tasks for users. These are sometimes referred to as \"rational agents.\"'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_parser.invoke({\"text\":text})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### json output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=PromptTemplate(\n",
    "    template=\"give me name, age and city from the provided text {text} \\n {format_instructions}\" ,\n",
    "    input_variables=['text'],\n",
    "    partial_variables={\"format_instructions\":parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"hi my name is sunny savita my age is 29 and i am belong to bengaluru\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=template.format(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'give me name, age and city from the provided text hi my name is sunny savita my age is 29 and i am belong to bengaluru \\n Return a JSON object.'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=openai_model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='{\\n\"name\": \"sunny savita\",\\n\"age\": 29,\\n\"city\": \"bengaluru\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 45, 'total_tokens': 71, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8ffe92fb-7a92-4eef-9e66-35549d7e53a8-0', usage_metadata={'input_tokens': 45, 'output_tokens': 26, 'total_tokens': 71, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"name\": \"sunny savita\",\\n\"age\": 29,\\n\"city\": \"bengaluru\"\\n}'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=parser.parse(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sunny savita'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bengaluru'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"city\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain= template | openai_model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sunny savita', 'age': 29, 'city': 'bengaluru'}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic=\"\"\"AI agent or simply agent), expands this concept by proactively pursuing goals, making decisions, and taking actions over extended periods, thereby exemplifying a novel form of digital agency.[1]\n",
    "\n",
    "Intelligent agents can range from simple to highly complex. A basic thermostat or control system is considered an intelligent agent, as is a human being, or any other system that meets the same criteria—such as a firm, a state, or a biome.[2]\n",
    "\n",
    "Intelligent agents operate based on an objective function, which encapsulates their goals. They are designed to create and execute plans that maximize the expected value of this function upon completion.[3] For example, a reinforcement learning agent has a reward function, which allows programmers to shape its desired behavior.[4] Similarly, an evolutionary algorithm's behavior is guided by a fitness function.[5]\n",
    "\n",
    "Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, and the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations.\n",
    "\n",
    "Intelligent agents are often described schematically as abstract functional systems similar to computer programs. To distinguish theoretical models from real-world implementations, abstract descriptions of intelligent agents are called abstract intelligent agents. Intelligent agents are also closely related to software agents—autonomous computer programs that carry out tasks on behalf of users. They are also referred to using a term borrowed from economics: a \"rational agent\".[2]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "template2=PromptTemplate(\n",
    "    template='Give me 5 facts about {topic} \\n {format_instruction}',\n",
    "    input_variables=['topic'],\n",
    "    partial_variables={'format_instruction': parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain= template2 | openai_model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Facts': [{'Fact 1': 'Intelligent agents can range from simple to highly complex. Basic systems like a thermostat or more complex entities like a human being or a state can be considered intelligent agents.'},\n",
       "  {'Fact 2': 'Intelligent agents operate based on an objective function that encapsulates their goals. They are designed to create and execute plans to maximize the expected value of this function.'},\n",
       "  {'Fact 3': 'The behavior of Intelligent agents like those using reinforcement learning have a reward function designed to inform their behavior while those using an evolutionary algorithm are guided by a fitness function.'},\n",
       "  {'Fact 4': 'Intelligent agents in artificial intelligence are closely related to agents in economics, and they are also studied in various fields like cognitive science, ethics, the philosophy of practical reason, and several interdisciplinary socio-cognitive modeling and computer social simulations.'},\n",
       "  {'Fact 5': 'Intelligent agents are often described schematically as abstract functional systems similar to computer programs. They can be theoretical models or real-world implementations. They are closely related to software agents, which are autonomous computer programs that carry out tasks on behalf of users.'}]}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": topic})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate a strcuture output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema=[\n",
    "    ResponseSchema(name=\"first_fact\", description=\"first fact about text\"),\n",
    "    ResponseSchema(name=\"second_fact\", description=\"second fact about text\"),\n",
    "    ResponseSchema(name=\"third_fact\", description=\"third fact about text\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=StructuredOutputParser.from_response_schemas(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "template3 = PromptTemplate(\n",
    "    template='Give 3 fact about {topic} \\n {format_instruction}',\n",
    "    input_variables=['topic'],\n",
    "    partial_variables={'format_instruction':parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template3 | openai_model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=chain.invoke({\"topic\":topic})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_fact': 'Intelligent agents can range from simple to highly complex, including systems like a basic thermostat or control system, a human being, or larger systems like a firm, a state, or a biome.', 'second_fact': 'Intelligent agents operate based on an objective function which encapsulates their goals, and they are designed to create and execute plans that maximize the expected value of this function upon completion.', 'third_fact': 'Intelligent agents in artificial intelligence are closely related to agents in economics, cognitive science, ethics, philosophy of practical reason, socio-cognitive modeling, and computer social simulations.'}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_fact': 'Intelligent agents can range from simple to highly complex, including systems like a basic thermostat or control system, a human being, or larger systems like a firm, a state, or a biome.', 'second_fact': 'Intelligent agents operate based on an objective function which encapsulates their goals, and they are designed to create and execute plans that maximize the expected value of this function upon completion.', 'third_fact': 'Intelligent agents in artificial intelligence are closely related to agents in economics, cognitive science, ethics, philosophy of practical reason, socio-cognitive modeling, and computer social simulations.'}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'first_fact': 'Intelligent agents can range from simple to highly complex, including systems like a basic thermostat or control system, a human being, or larger systems like a firm, a state, or a biome.', 'second_fact': 'Intelligent agents operate based on an objective function which encapsulates their goals, and they are designed to create and execute plans that maximize the expected value of this function upon completion.', 'third_fact': 'Intelligent agents in artificial intelligence are closely related to agents in economics, cognitive science, ethics, philosophy of practical reason, socio-cognitive modeling, and computer social simulations.'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydantic Output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person(BaseModel):\n",
    "    name:str=Field(description=\"name of person\")\n",
    "    age:int=Field(gt=18,description=\"age of person\")\n",
    "    city:str=Field(description=\"name of the city where the person is located\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=PydanticOutputParser(pydantic_object=Person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"description\": \"name of person\", \"title\": \"Name\", \"type\": \"string\"}, \"age\": {\"description\": \"age of person\", \"exclusiveMinimum\": 18, \"title\": \"Age\", \"type\": \"integer\"}, \"city\": {\"description\": \"name of the city where the person is located\", \"title\": \"City\", \"type\": \"string\"}}, \"required\": [\"name\", \"age\", \"city\"]}\\n```'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate(\n",
    "    template='Generate the nammme, age and city of a fictional {place} person \\n {format_instruction}',\n",
    "    input_variables=['place'],\n",
    "    partial_variables={'format_instruction':parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | openai_model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=chain.invoke({\"place\":\"bengaluru\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Rohit Sharma', age=29, city='Bengaluru')"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rohit Sharma\n"
     ]
    }
   ],
   "source": [
    "print(result.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "print(result.age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@vidiptvashist/building-a-vector-database-from-scratch-in-python-6bd683ba5171\n",
    "https://medium.com/data-and-beyond/vector-databases-a-beginners-guide-b050cbbe9ca0\n",
    "https://nexla.com/ai-infrastructure/vector-databases/\n",
    "https://www.geeksforgeeks.org/what-is-a-vector-database/\n",
    "https://lakefs.io/blog/12-vector-databases-2023/\n",
    "chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectordatabase #textsplitter\n",
    "1. pinecone(cloud vdb),weviate\n",
    "#2. weviate, qurdant,milvus\n",
    "3. mongodb\n",
    "4. faiss, chroma(in memory)#poc\n",
    "5. on disk(persist vectordb on disk)\n",
    "6. aws opensearch\n",
    "\n",
    "embdding, meta_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://readmedium.com/en/https:/medium.com/@harsh.vardhan7695/mastering-text-splitting-in-langchain-735313216e01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# Original Text\n",
    "text = \"\"\"LangChain is a powerful framework for building LLM applications. It helps in connecting language models with data sources, APIs, and other components. One of its key features is text processing, where it allows splitting large documents into smaller chunks. This is useful for vector databases, retrieval-augmented generation (RAG), and long-context handling. Another feature is its integration with various AI tools and libraries. This makes LangChain a great choice for developers working on AI-powered applications.\n",
    "\n",
    "LangChain provides seamless support for working with embeddings and vector databases, allowing efficient document retrieval and query resolution. It also simplifies prompt engineering, making it easier to design structured prompts for LLMs. Developers can use LangChain to build sophisticated AI chatbots, content generators, and even research assistants.\n",
    "\n",
    "The framework supports multiple LLM providers, including OpenAI, Hugging Face, and local models like Llama and Mistral. It offers various chain types, such as sequential and parallel chains, enabling flexible workflow automation. LangChain's integration with tools like Pinecone, ChromaDB, and FAISS ensures fast and scalable search capabilities.\n",
    "\n",
    "With built-in memory components, LangChain allows chatbots and virtual assistants to maintain context over extended interactions. This helps in creating human-like conversations that feel more natural. Furthermore, LangChain supports function calling and API interaction, making it ideal for building AI-powered applications that require external data fetching.\n",
    "\n",
    "The ecosystem also includes template-based prompt handling, making it easier to experiment with different LLM configurations. Developers can fine-tune their models, optimize performance, and integrate LangChain with various cloud-based AI solutions. Whether for research, automation, or enterprise applications, LangChain stands out as a robust and flexible framework for AI development.\n",
    ".\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the splitter\n",
    "splitter = CharacterTextSplitter( \n",
    "    separator=\"\\n\",\n",
    "    chunk_size=200,    \n",
    "    chunk_overlap=50 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 518, which is longer than the specified 200\n",
      "Created a chunk of size 355, which is longer than the specified 200\n",
      "Created a chunk of size 346, which is longer than the specified 200\n",
      "Created a chunk of size 361, which is longer than the specified 200\n",
      "Created a chunk of size 387, which is longer than the specified 200\n"
     ]
    }
   ],
   "source": [
    "# Splitting the text\n",
    "chunks = splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LangChain is a powerful framework for building LLM applications. It helps in connecting language models with data sources, APIs, and other components. One of its key features is text processing, where it allows splitting large documents into smaller chunks. This is useful for vector databases, retrieval-augmented generation (RAG), and long-context handling. Another feature is its integration with various AI tools and libraries. This makes LangChain a great choice for developers working on AI-powered applications.',\n",
       " 'LangChain provides seamless support for working with embeddings and vector databases, allowing efficient document retrieval and query resolution. It also simplifies prompt engineering, making it easier to design structured prompts for LLMs. Developers can use LangChain to build sophisticated AI chatbots, content generators, and even research assistants.',\n",
       " \"The framework supports multiple LLM providers, including OpenAI, Hugging Face, and local models like Llama and Mistral. It offers various chain types, such as sequential and parallel chains, enabling flexible workflow automation. LangChain's integration with tools like Pinecone, ChromaDB, and FAISS ensures fast and scalable search capabilities.\",\n",
       " 'With built-in memory components, LangChain allows chatbots and virtual assistants to maintain context over extended interactions. This helps in creating human-like conversations that feel more natural. Furthermore, LangChain supports function calling and API interaction, making it ideal for building AI-powered applications that require external data fetching.',\n",
       " 'The ecosystem also includes template-based prompt handling, making it easier to experiment with different LLM configurations. Developers can fine-tune their models, optimize performance, and integrate LangChain with various cloud-based AI solutions. Whether for research, automation, or enterprise applications, LangChain stands out as a robust and flexible framework for AI development.',\n",
       " '.']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "LangChain is a powerful framework for building LLM applications. It helps in connecting language models with data sources, APIs, and other components. One of its key features is text processing, where it allows splitting large documents into smaller chunks. This is useful for vector databases, retrieval-augmented generation (RAG), and long-context handling. Another feature is its integration with various AI tools and libraries. This makes LangChain a great choice for developers working on AI-powered applications.\n",
      "--------------------------------------------------\n",
      "Chunk 2:\n",
      "LangChain provides seamless support for working with embeddings and vector databases, allowing efficient document retrieval and query resolution. It also simplifies prompt engineering, making it easier to design structured prompts for LLMs. Developers can use LangChain to build sophisticated AI chatbots, content generators, and even research assistants.\n",
      "--------------------------------------------------\n",
      "Chunk 3:\n",
      "The framework supports multiple LLM providers, including OpenAI, Hugging Face, and local models like Llama and Mistral. It offers various chain types, such as sequential and parallel chains, enabling flexible workflow automation. LangChain's integration with tools like Pinecone, ChromaDB, and FAISS ensures fast and scalable search capabilities.\n",
      "--------------------------------------------------\n",
      "Chunk 4:\n",
      "With built-in memory components, LangChain allows chatbots and virtual assistants to maintain context over extended interactions. This helps in creating human-like conversations that feel more natural. Furthermore, LangChain supports function calling and API interaction, making it ideal for building AI-powered applications that require external data fetching.\n",
      "--------------------------------------------------\n",
      "Chunk 5:\n",
      "The ecosystem also includes template-based prompt handling, making it easier to experiment with different LLM configurations. Developers can fine-tune their models, optimize performance, and integrate LangChain with various cloud-based AI solutions. Whether for research, automation, or enterprise applications, LangChain stands out as a robust and flexible framework for AI development.\n",
      "--------------------------------------------------\n",
      "Chunk 6:\n",
      ".\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Printing the chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}:\\n{chunk}\\n{'-'*50}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LangChain is a powerful framework for building LLM applications. It helps in connecting language models with data sources, APIs, and other components. One of its key features is text processing, where it allows splitting large documents into smaller chunks. This is useful for vector databases, retrieval-augmented generation (RAG), and long-context handling. Another feature is its integration with various AI tools and libraries. This makes LangChain a great choice for developers working on AI-powered applications.\\n\\nLangChain provides seamless support for working with embeddings and vector databases, allowing efficient document retrieval and query resolution. It also simplifies prompt engineering, making it easier to design structured prompts for LLMs. Developers can use LangChain to build sophisticated AI chatbots, content generators, and even research assistants.',\n",
       " \"The framework supports multiple LLM providers, including OpenAI, Hugging Face, and local models like Llama and Mistral. It offers various chain types, such as sequential and parallel chains, enabling flexible workflow automation. LangChain's integration with tools like Pinecone, ChromaDB, and FAISS ensures fast and scalable search capabilities.\\n\\nWith built-in memory components, LangChain allows chatbots and virtual assistants to maintain context over extended interactions. This helps in creating human-like conversations that feel more natural. Furthermore, LangChain supports function calling and API interaction, making it ideal for building AI-powered applications that require external data fetching.\",\n",
       " 'The ecosystem also includes template-based prompt handling, making it easier to experiment with different LLM configurations. Developers can fine-tune their models, optimize performance, and integrate LangChain with various cloud-based AI solutions. Whether for research, automation, or enterprise applications, LangChain stands out as a robust and flexible framework for AI development.\\n.']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "splitter = TokenTextSplitter(\n",
    "    encoding_name=\"cl100k_base\",  # OpenAI's encoding\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "LangChain is a powerful framework for building LLM applications. It helps in connecting language models with data sources, APIs, and other components. One of its key features is text processing, where it allows splitting large documents into smaller chunks. This is useful for vector databases, retrieval-augmented generation (RAG), and long-context handling. Another feature is its integration with various AI tools and libraries. This makes LangChain a great choice for developers working on AI-powered applications.\n",
      "\n",
      "LangChain provides seamless support\n",
      "--------------------------------------------------\n",
      "Chunk 2:\n",
      " This makes LangChain a great choice for developers working on AI-powered applications.\n",
      "\n",
      "LangChain provides seamless support for working with embeddings and vector databases, allowing efficient document retrieval and query resolution. It also simplifies prompt engineering, making it easier to design structured prompts for LLMs. Developers can use LangChain to build sophisticated AI chatbots, content generators, and even research assistants.\n",
      "\n",
      "The framework supports multiple LLM providers, including OpenAI, Hugging Face, and local models like Llama and Mistral\n",
      "--------------------------------------------------\n",
      "Chunk 3:\n",
      "LM providers, including OpenAI, Hugging Face, and local models like Llama and Mistral. It offers various chain types, such as sequential and parallel chains, enabling flexible workflow automation. LangChain's integration with tools like Pinecone, ChromaDB, and FAISS ensures fast and scalable search capabilities.\n",
      "\n",
      "With built-in memory components, LangChain allows chatbots and virtual assistants to maintain context over extended interactions. This helps in creating human-like conversations that feel more natural. Furthermore, LangChain\n",
      "--------------------------------------------------\n",
      "Chunk 4:\n",
      " over extended interactions. This helps in creating human-like conversations that feel more natural. Furthermore, LangChain supports function calling and API interaction, making it ideal for building AI-powered applications that require external data fetching.\n",
      "\n",
      "The ecosystem also includes template-based prompt handling, making it easier to experiment with different LLM configurations. Developers can fine-tune their models, optimize performance, and integrate LangChain with various cloud-based AI solutions. Whether for research, automation, or enterprise applications, LangChain stands out as a robust\n",
      "--------------------------------------------------\n",
      "Chunk 5:\n",
      " AI solutions. Whether for research, automation, or enterprise applications, LangChain stands out as a robust and flexible framework for AI development.\n",
      ".\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Printing the chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}:\\n{chunk}\\n{'-'*50}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
